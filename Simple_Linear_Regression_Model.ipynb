{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wewerthonc/AI-projects/blob/main/Simple_Linear_Regression_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X6HJdTAnBso2"
      },
      "outputs": [],
      "source": [
        "import math, random, tqdm\n",
        "from typing import List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D2mswe8RCXer"
      },
      "outputs": [],
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self) -> None:\n",
        "    random.seed(0)\n",
        "    self.alpha: float = random.random();\n",
        "    self.beta: float = random.random();\n",
        "  \n",
        "  def _error(self, x_i: float, y_i: float) -> float:\n",
        "    \"\"\"Error function\"\"\"\n",
        "    return self.predict(x_i) - y_i\n",
        "\n",
        "  def _loss(self, x: List[float], y: List[float]) -> float:\n",
        "    \"\"\"Squared Error Fuction\"\"\"\n",
        "    return sum(self._error(x_i, y_i) ** 2 for x_i, y_i in zip(x, y))\n",
        "  \n",
        "  def _gradient_step(self, v: List[float], gradient: List[float], step_size: float) -> List[float]:\n",
        "\n",
        "    #Multiplies all the elements of the vector by step_size\n",
        "    step = [step_size * v_i for v_i in gradient]\n",
        "\n",
        "    #Sums corresponding elements of v and step\n",
        "    new_guess = [v_i + s_i for v_i, s_i in zip(v, step)]\n",
        "\n",
        "    return new_guess\n",
        "\n",
        "  def train(self, x: List[float], y: List[float], \n",
        "            num_epochs: float, learning_rate = 0.0001) -> None:\n",
        "    \"\"\"Trains the model using gradient descent\"\"\"\n",
        "    \n",
        "    guess = [self.alpha, self.beta]\n",
        "\n",
        "    with tqdm.trange(num_epochs) as t:\n",
        "      for _ in t:\n",
        "        # Partial derivative of loss with respect to alpha\n",
        "        grad_alpha = sum(2 * self._error(x_i, y_i)\n",
        "                        for x_i, y_i in zip(x, y))\n",
        "        \n",
        "        # Partial derivative of loss with respect to beta\n",
        "        grad_beta = sum(2 * self._error(x_i, y_i) * x_i \n",
        "                         for x_i, y_i in zip(x, y))\n",
        "        \n",
        "        # Compute loss to stick in the tqdm description\n",
        "        loss = self._loss(x, y)\n",
        "        t.set_description(f\"loss: {loss:.3f}\")\n",
        "\n",
        "        # Update alpha and beta using gradient descent\n",
        "        guess = self._gradient_step(guess, [grad_alpha, grad_beta], -learning_rate)\n",
        "        self.alpha, self.beta = guess\n",
        "\n",
        "  def predict(self, x_i: float) -> float:\n",
        "    return self.beta * x_i + self.alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gB0B3F0iVDTy"
      },
      "outputs": [],
      "source": [
        "x = [i for i in range(0, 5)]\n",
        "y = [5 * i  + 1 for i in range(0, 5)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SMoMdenVFAU",
        "outputId": "36240ac2-4211-40fa-ca6e-753efb30b618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.006: 100%|██████████| 50/50 [00:00<00:00, 739.87it/s]\n"
          ]
        }
      ],
      "source": [
        "linear_model = LinearRegression()\n",
        "linear_model.train(x, y, 50, 0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eH_KNSJXe1i",
        "outputId": "7775fdfb-7073-4adc-ab1c-a29db103977d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0, 1, 2, 3, 4], [1, 6, 11, 16, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sjixZg_Zo5s",
        "outputId": "8d99bc47-2287-4a8c-b231-c69062251fe8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.035502023187647"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "linear_model.predict(1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Simple_Linear_Regression_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOA6ofVP/w4EQ58aaim+JJB",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}